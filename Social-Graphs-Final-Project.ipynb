{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset - Spotify mining\n",
    "\n",
    "\n",
    "#### To achieve all the aformentioned goals, we first defined the data that we would use on our analysis.\n",
    "\n",
    "We decided to extract all the data we need from ***Spotify***.\n",
    "\n",
    "Spotify is probably one of the most well-known music streaming platforms all over the world. It contains more than 40 millions of tracks that users can listen to thanks to their multi-platform web and mobile applications. \n",
    "\n",
    "But in this case, we are mostly interested in the Spotify Web API endpoints. Using them, we have been able to obtain our desired information about music artists, albums, and tracks directly from the Spotify Data Catalogue. Furthermore, we have also been interested in obtaining calculated audio features of tracks.\n",
    "\n",
    "The functions used to download our desired data are the following ones:\n",
    "\n",
    "* Search by genre\n",
    "* Get an Artist's Top Tracks\n",
    "* Get an Artist's Albums\n",
    "* Get an Album's Tracks\n",
    "* Get a Track\n",
    "* Get Song's audio features\n",
    "\n",
    "To actually download all data needed, we have used the already existing Spotify library for Python (_Spotipy_). In order to use it, we first had to get credentials that Spotify asks. Anyone can ask for these credentials through the Spotify Website.\n",
    "\n",
    "\n",
    "### We found where we get the data from! Now what?\n",
    "\n",
    "The amount music data availabe though way big! At first it was a bit overwhelming,but to make thing more realistic, but also keep reliability in our work, we agreed in the following flow of actions:\n",
    "\n",
    "- Retrive the ***Top 100 Artists*** of ***7 Top Genre's*** of Spotify. This totals to _700 Artists_.\n",
    "- Fetch the current ***Top 10 songs of each Artist***.\n",
    "- Find the ***collaborations*** of each Artist, by mining each Artist's albms.\n",
    "- Get ***audio features*** of each one of these songs.\n",
    "- **Mine** the lyrics of each one of these songs.\n",
    "\n",
    "The genres we decided to retrieve songs from are the following:\n",
    "\n",
    "* Pop\n",
    "* Rock\n",
    "* Hip-hop\n",
    "* Blues\n",
    "* Indie\n",
    "* Country\n",
    "* Soul"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic stats. Let's understand the dataset better\n",
    "\n",
    "### The installation and code developed to use the Spotify API is the folowing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import needed libraries\n",
    "import sys\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "import spotipy\n",
    "import pprint\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Spotify autentification credentials\n",
    "client_id = \"b06999e849764d0cb9d85ff2b4762fd9\"\n",
    "client_secret = \"4565b9044d694deb9cf54eddb9b08e69\"\n",
    "\n",
    "client_credentials_manager = SpotifyClientCredentials(client_id=client_id, client_secret=client_secret)\n",
    "sp = spotipy.Spotify(client_credentials_manager=client_credentials_manager)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Artist's Dataset (artists.csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, the artists' list of top 100 artists for each genre has been created. In this case, the *Search by genre* endpoint has been used by assigning that the type of the response information desired is artist. The maximum length of objects on each response that Spotify allows is just 50, so we needed to make the call twice by using the parameters *limit* and *offset* to obtain our information desired.\n",
    "\n",
    "The downloaded list of artists has been saved on *artists.csv* file and for each artist, the following information has been kept.\n",
    "\n",
    "* Artist\n",
    "* Genre\n",
    "* Artist uri\n",
    "* Artist id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Download the top 100 artists for each genre defined\n",
    "def downloadTopArtistsGenre(genres):\n",
    "  #Open \n",
    "  file = open(\"artists.csv\", \"w+\")\n",
    "  fileCsv = csv.writer(file)\n",
    "  fileCsv.writerow(['Artist','Genre','Artist_uri','Artist_id'])\n",
    "  for genre in genres:\n",
    "    result = sp.search(q='genre:'+genre, type='artist',limit=50,offset=0)\n",
    "    for artist in result['artists']['items']:\n",
    "      #artist JSON dict like: https://developer.spotify.com/documentation/web-api/reference/artists/get-artist/\n",
    "      row = [artist['name'].encode('ascii', 'ignore'),genre,artist['uri'].encode('ascii', 'ignore'),artist['id'].encode('ascii', 'ignore')]\n",
    "      fileCsv.writerow(row)\n",
    "    result = sp.search(q='genre:'+genre, type='artist',limit=50,offset=50)\n",
    "    for artist in result['artists']['items']:\n",
    "      row = [artist['name'].encode('ascii', 'ignore'),genre,artist['uri'].encode('ascii', 'ignore'),artist['id'].encode('ascii', 'ignore')]\n",
    "      fileCsv.writerow(row)\n",
    "  file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Genres defined\n",
    "genres = ['pop','rock','hip-hop','blues','indie','country','soul']\n",
    "downloadTopArtistsGenre(genres)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afterwards, the collaborations for each artist wanted to be retrieved. To do it, we had to obtain the list of songs for each artist and then checked if the song has multiple artists or not.\n",
    "\n",
    "As the Spotify platform does not allow to directly obtain the songs for each artist, first all the albums for each artist were obtained again with the *limit* and *offset* parameters. And then, for each album retrieved, all songs were downloaded and analyzed. A similar procedure was executed for the singles of each artist to obtain as much information as possible related to collaborations because we realized that some remix songs created were not included in an album. This time, we just retrieved, at maximum 50 singles for each artist.\n",
    "\n",
    "Furthermore, we realized that we had to exclude the *compilation* albums and lists retrieved on the same service because, otherwise, information regarding the list of reproductions created by Spotify was also retrieved and processed on our creation of the graph.\n",
    "\n",
    "In this step, we decided to do not filter the collaborations within our list of artists, as it would be nice to also abstract some information from the other collaborations at some point of our further analysis. That is why, each time that more than one artists were found on a song, a new entry was added to the *artists_colab.csv* or *artists_colab_singles.csv* files with the following format without any other filtering.\n",
    "\n",
    "* Artist\n",
    "* Artist id\n",
    "* Artist colab.\n",
    "* Artist colab. id\n",
    "* Song\n",
    "* Song id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Downloaded all colaborations of one artist based on his albums\n",
    "def downloadColaborationsPerArtistsAlbums(artistsList):\n",
    "  file = open(\"artists_colab.csv\", \"w+\")\n",
    "  fileCsv = csv.writer(file)\n",
    "  fileCsv.writerow(['Artist', 'Artist_id', 'ArtistColab','ArtistColab_id', 'Song', 'Song_id'])\n",
    "\n",
    "  artistsCol = list()\n",
    "  for index, artist in artistsList.iterrows():\n",
    "    total = 1\n",
    "    offset = 0\n",
    "    while(offset < total):\n",
    "      result = sp.artist_albums(artist['Artist_uri'], limit=50, album_type='album', offset=offset)\n",
    "      for album in result['items']:\n",
    "        if (album['album_type'] != 'Compilation'):\n",
    "          result1 = sp.album_tracks(album['uri'], limit=50)\n",
    "          for song in result1['items']:   \n",
    "            for art in song['artists']:\n",
    "              # tests if art in artists - take only links between the top artists\n",
    "              if(artist['Artist'] != art['name']):\n",
    "                artistsCol.append(art['name'])\n",
    "                row = [artist['Artist'].encode('ascii', 'ignore'), artist['Artist_id'].encode('ascii', 'ignore'), art['name'].encode('ascii', 'ignore'),art['id'].encode('ascii', 'ignore'),song['name'].encode('ascii', 'ignore'), song['id'].encode('ascii', 'ignore')]\n",
    "                fileCsv.writerow(row)\n",
    "      if (offset == 0):\n",
    "        total = result['total']\n",
    "      offset += 1\n",
    "  print(\"Done\")\n",
    "  file.close()\n",
    "\n",
    "#Downloaded all colaborations of one artist based on his singles\n",
    "def downloadColaborationsPerArtistsSingles(artistsList):\n",
    "  file = open(\"artists_colab_singles.csv\", \"w+\")\n",
    "  fileCsv = csv.writer(file)\n",
    "  fileCsv.writerow(['Artist', 'Artist_id', 'ArtistColab','ArtistColab_id', 'Song', 'Song_id'])\n",
    "  artistsCol = list()\n",
    "  for index, artist in artistsList.iterrows():\n",
    "    result = sp.artist_albums(artist['Artist_uri'], limit=50, album_type='single', offset=0)\n",
    "    for album in result['items']:\n",
    "      if (album['album_type'] != 'Compilation'):\n",
    "        result1 = sp.album_tracks(album['uri'], limit=50)\n",
    "        for song in result1['items']:   \n",
    "          for art in song['artists']:\n",
    "            # tests if art in artists - take only links between the top artists\n",
    "            if(artist['Artist'] != art['name']):\n",
    "              artistsCol.append(art['name'])\n",
    "              row = [artist['Artist'].encode('ascii', 'ignore'), artist['Artist_id'].encode('ascii', 'ignore'), art['name'].encode('ascii', 'ignore'),art['id'].encode('ascii', 'ignore'),song['name'].encode('ascii', 'ignore'), song['id'].encode('ascii', 'ignore')]\n",
    "              fileCsv.writerow(row)\n",
    "  print(\"Done\")\n",
    "  file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load artists form the previous saved file\n",
    "artistsList = pd.read_csv('./SGI_Sportify_Project/artists.csv', encoding='utf-8')\n",
    "#Create artists_colab.csv file\n",
    "downloadColaborationsPerArtistsAlbums(artistsList)\n",
    "#Create artists_colab_singles.csv file\n",
    "downloadColaborationsPerArtistsSingles(artistsList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Songs Dataset (topsters_all.csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset used for the Network of Song Similaruty is the topsters_all.csv. It contains information about the top 10 songs, of top 10 artists, of all genres. To create this we were based on the artists.csv\n",
    "\n",
    "To obtain all the relevant data for this particular dataset, we also used the Spotify Library of Python (Spotipy).\n",
    "After mining Spotify data, we got the elements needed , by mainly using the following functins:\n",
    "\n",
    ">sp.artist_top_tracks<br>\n",
    "sp.audio_features\n",
    "\n",
    "The topsters_all.csv contains the following data in order.\n",
    ">- **Genre**: A list, which contains the genre(s) that the song belongs to. To do this we \"borrowed\" the genre(s) of the relevant artist from the artists.csv.\n",
    "- **Artist**: The artist's name.\n",
    "- **Artist_id**: Spotify API assigns a unique ID to each Artist.\n",
    "- **Song**: The name of the song.\n",
    "- **Song_id**: Similarly with Artists, Spotify API assigns a unique ID TO each song. This way you can distinguish to songs that might share the same name.\n",
    "- **Audio_Metric**: A vector of 3 elements. Each of these elements is a particular audio feature. Namely, _Valence_, _Energy_ and _Dancebility_. We got those features by mining the Spotify API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To gather the data for the topsters_all.csv, **we were based on the artists.csv**, from which we retrieved every artist. Having ecery artist, leaves with one thing. That is to get the **top 10 songs** of each one.\n",
    "\n",
    "#### The first issue that we encountered was that the artists.csv contains a number duplicate artists.<br>\n",
    "> ***Why this happens is explained below:<br>***\n",
    "To obtain the aritsts.csv we downloaded each genre's 100 most popular artists. However, there are artists associated with more than one genres, thus they appear more than once in the artists.csv<br><br>\n",
    ">**In the topsters_all.csv we want every song to occur only once, but we also need to keep all the different genres that this song is associated with.**<br><br>\n",
    ">To do this we make a list of all the genres that the artist of the respective song is associated with, and assign this list as the song's genre. \n",
    "(Unfortunately the Spotify API does not directly return the genre(s) of a particualar song, that is why we assign the corresponding artist's genre(s).\n",
    "\n",
    "#### The second issue was that we still encountered duplicate songs.<br>\n",
    "> ***Why this happens is explained below:***<br>\n",
    "Since two artists might have collaborated on a very popular song, this song will appear on both artist's top 10 list.<br><br>\n",
    "> This was solved by creating a list where in every iteration we test if every new song is already in the list. If not we append it and write the song in csv. If it is already in the list we skip it. We keep doing that until we have finished with all songs.<br><br>\n",
    "> Yes. Since the genre we assign to each song, is the genre of it's artist, if a popular song \"belongs\" to two artists and we skip one of them, it is possible that we miss a genre. However, we assume that the two collaborating artists, most likely belong to the same genre(s), and there is no important \"loss\" of data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ***Below is the code for obtaining the topsters_all.csv***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the topsters_all1.csv\n",
    "path = \"topsters_all.csv\"\n",
    "songs = [] # create a list, where every song will be appended at a time\n",
    "\n",
    "with open(path, \"wb\") as f:\n",
    "    top_tracks_csv = csv.writer(f)\n",
    "    top_tracks_csv.writerow(['Genre', 'Artist', 'Artist_id', 'Song', 'Song_id', 'Audio_Metric'])\n",
    "    \n",
    "    for index, row in artists_df.iterrows():\n",
    "        artist_id = row['Artist_id']\n",
    "        artist_name = row['Artist']\n",
    "        genre = list(artists_df.loc[artists_df['Artist_id'] == artist_id][\"Genre\"]) # geta list of every artist's genre(s)\n",
    "        top_tracks_list = sp.artist_top_tracks(artist_id)['tracks'] # get top 10 tracks of every artist by the Spotify API\n",
    "        for song in top_tracks_list:\n",
    "            try:\n",
    "                song_id = song['id']\n",
    "                if song_id not in songs:# check if the song is already written in the csv.\n",
    "                    songs.append(song_id)\n",
    "                    audio_features = sp.audio_features([song_id])[0]\n",
    "                    #in the three following lines I round the song features into two decimals.\n",
    "                    valence = round(audio_features['valence'],2)\n",
    "                    energy = round(audio_features['energy'],2)\n",
    "                    danceability = round(audio_features['danceability'],2)\n",
    "                    audio_metric = [valence, energy, danceability] # create the audio_metric vector\n",
    "                    row = [genre, artist_name.encode('ascii', 'ignore'), str(artist_id).encode('ascii', 'ignore'), song['name'].encode('ascii', 'ignore'), str(song['id']).encode('ascii', 'ignore'), audio_metric]\n",
    "                    top_tracks_csv.writerow(row)\n",
    "            except:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the topsters_all.csv, to create the songs_df and use it later on, in the Network creation and analysis\n",
    "songs_df = pd.read_csv(r\"topsters_all.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topsters Datasets (/topsters/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Up\n",
    "Below we set up the libraries for this notebook. All needed libraries are imported here. \n",
    "\n",
    "If you lack a library, or experience any kind of issues please refer to the bottom of the page to find the exact versions of the libraries used (retrieved with `pip freeze`). You can always install a library on-the-fly on your notebook with `!pip install library`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "import spotipy\n",
    "import pprint\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import time\n",
    "import math\n",
    "import os\n",
    "from os import path\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from wordcloud import WordCloud, ImageColorGenerator\n",
    "from nltk.collocations import *\n",
    "import seaborn as sns\n",
    "import joypy\n",
    "import matplotlib.cm as cm\n",
    "import random\n",
    "import socket #for lyric fetching\n",
    "from nltk.stem.porter import *\n",
    "from textblob import TextBlob\n",
    "from nltk.corpus import stopwords "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#libraries to fetch lyrics\n",
    "from azlyrics import lyrics\n",
    "import pandas as pd\n",
    "import re\n",
    "import lyricwikia\n",
    "import urllib2\n",
    "import json\n",
    "import bs4\n",
    "import requests\n",
    "import unicodedata\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be creating two directories on our system:\n",
    "- `lyrics` is going to hold the lyrics in .csv files, presented by song and divided in files by Arist\n",
    "- `topsters` is going to hold the Top 10 songs in .csv files, divided by Artist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A subdirectory or file lyrics already exists.\n"
     ]
    }
   ],
   "source": [
    "mkdir lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A subdirectory or file topsters already exists.\n"
     ]
    }
   ],
   "source": [
    "mkdir topsters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we load the necessary Top 700 Artist data from the corresponding `.csv`.\n",
    "\n",
    "It is necessary to save that data as the Top 700 Artist data can change based on the data fecthed by Spotify. That, inherently creates the need of fectching the lyrics of any Artist that recently made it on the Top 700 and, as we will see afterwards, this can be time consuming.\n",
    "\n",
    "Thus, to have a common basis of discussion for the full length of our report, we are using the same `.csv` files throughout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SETTING THE DATAFRAMES WE NEED HERE\n",
    "artists_df = pd.read_csv('artists.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, you will find our Spotify credentials. They are needed to fecth data from their REST API endpoints. \n",
    "\n",
    "Since they are ours, please respect [Spotify's Developers ToS](https://developer.spotify.com/terms/) when you are using our code.\n",
    "\n",
    "Furthermore, we are creating a Spotify client object to enact any calls needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_id = \"b06999e849764d0cb9d85ff2b4762fd9\"\n",
    "client_secret = \"4565b9044d694deb9cf54eddb9b08e69\"\n",
    "\n",
    "client_credentials_manager = SpotifyClientCredentials(client_id=client_id, client_secret=client_secret)\n",
    "sp = spotipy.Spotify(client_credentials_manager=client_credentials_manager)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we are fetching the Top 10 songs (_topsters_) for each one of the Top 700 Artists and putting them inside corrsponding `.csv` files. Each `.csv` will have rows that hold the following information: _'Artist', 'Artist id', 'Song', 'Song id'_.\n",
    "\n",
    "The code segment includes a performance provision, skipping the calls if a _topster_ file already exists for an _Artist_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "counter_dup = 0\n",
    "import os.path\n",
    "for index, row in artists_df.iterrows():\n",
    "    counter += 1\n",
    "    # have overview of how soon this code segment is done\n",
    "    if (counter % 10 == 0):\n",
    "        #print(counter)\n",
    "        pass\n",
    "    artist_id = row['Artist_id']\n",
    "    artist_name = row['Artist']\n",
    "    try:\n",
    "        # do not query if we already have the information\n",
    "        if (os.path.exists(\"./topsters/songs_\"+str(artist_id)+\".csv\")):\n",
    "            counter_dup += 1\n",
    "            continue\n",
    "        fileCsv2 = csv.writer(open(\"./topsters/songs_\"+str(artist_id)+\".csv\", \"w+\"))\n",
    "        fileCsv2.writerow(['Artist', 'Artist_id', 'Song', 'Song_id'])\n",
    "        top_track_list = sp.artist_top_tracks(str(artist_id))['tracks']\n",
    "    except:\n",
    "        #print(artist_id)\n",
    "        pass\n",
    "    for track in top_track_list:\n",
    "        row = [artist_name.encode('ascii', 'ignore'),str(artist_id).encode('ascii', 'ignore'),track['name'].encode('ascii', 'ignore'), track['id'].encode('ascii', 'ignore')]\n",
    "        fileCsv2.writerow(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lyrics Mining (/lyrics/)\n",
    "Lyric mining is a challenging task. This falls under the caveats of our venture. As with the challenges we faced with data preparation from Spotify, lyric mining would become the next big hurdle for us. To successfuly manage to attain the lyrics for our songs we've had to resort in using a mix of services. A simpler solution would be to use the [Musicmatch API](https://developer.musixmatch.com/) which offers direct access to the data we need.  \n",
    "\n",
    "We have decided to refrain from using that API because:\n",
    "- The free available version of their service is limited to 2000 requests per day and only 30% of the song. Even though the first part of the problem can be dealt with, by mining on consecutive days, the second part would be a roadblock for a meaningful lyrical analysis.\n",
    "- [The costs are very high](https://developer.musixmatch.com/plans) for the amount of data we need.\n",
    "\n",
    "Regardless, it is interesting to note that Musicmatch is [offering solutions](https://developer.musixmatch.com/ai)  that can greatly resemble the possibilities that one has by enhancing the solutions described in our research. \n",
    "\n",
    "Concequently, we have utilized three methods of attaining lyrics:\n",
    "1. __AZLyrics__: We directly mine their website for the song in question (using the available `azlyrics` library). AZLyrics offers one of the most comprehensive, open libraries for lyrics. Unfortunately, they impose a Rate Limit on the requests one can make on their website. The Rate Limit itself is unknown and once reached the client's IP is banned for an, also, unknown amount of time.\n",
    "2. __LyricWikia__: Our method (through the corresponding library) also uses HTTP requests. Although there are no Rate Limits that seem to be restrictive with this solution, LyricWikia's library is not completely comprehensive.\n",
    "3. __Genius__: Genius's library of lyrics is focused in (and started from) Hip-Hop and Pop songs. Regardless, in the last years there has been a surge of new lyric pages of more genres. This solution was designated to be a last resort. Genius does not offer an endpoint to retrieve lyrics (the closest would be `/songs/:id`, but it is essentialy the same as an HTTP request of the website) but rather one to search using their search engines and fetch the result. Thus when finding a possible match for a song, we would mine the song's page and parse it with Beautiful Soup. This leads us to conduct two API queries to receive a result from Genius and thus, due to its increased time requirements. Regardless, Genius is used extensively in the final solution, as LyricWikia can drop the ball in terms of finding lesser known songs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, you will find our Genius API credentials. They are needed to fecth data from their REST API endpoints. \n",
    "\n",
    "Since they are ours and you are granted access for the purposes of this report, please respect [Genius's ToS](https://genius.com/static/terms) when you are using our code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "genius_api_dict = {'id':'eOFdp-v__I7JeKporMF3K49wKnz3cYIkJcOGUP1wRz2uV7AmWh1eeBup_zJMCkqA',\n",
    "              'secret': 'kbbVWQxhXtsfnHm1W65gkjnvxlt9A3U2ih5bf6KWBJe6_KeYWZWyxC4rDK62OX9OQ9cLWTH0FgKZWoRmEofH9g',\n",
    "              'access_token': 'jhpqKVzO880gvQ5i-JkEh08wTUhmmA4kMuCkt5MQKLKMrWnjjqs3Z0WiVd49TmR7'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the section below, we define a series of __utility functions__ that will allow us to fetch the lyrics for every song.\n",
    "\n",
    "First and foremost, we define the function to fetch algoritms from Genius. It follows the thinking we mentioned before:\n",
    "1. A search is conducted in Genius's engine using the artist name and title of the song\n",
    "2. The first result is taken and its page HTML is fetched\n",
    "3. The HTML is parsed with Beautiful Soup, taking lyrics and concluding if the corresponding song is the correct one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genius_Lyrics(artist, song):\n",
    "    querystring = \"http://api.genius.com/search?q=\" + urllib2.quote(song + \" \" + artist)\n",
    "    request = urllib2.Request(querystring)\n",
    "    request.add_header(\"Authorization\", \"Bearer \" + genius_api_dict['access_token'])   \n",
    "    request.add_header(\"User-Agent\", \"curl/7.9.8 (i686-pc-linux-gnu) libcurl 7.9.8 (OpenSSL 0.9.6b) (ipv6 enabled)\") #Must include user agent of some sort, otherwise 403 returned\n",
    "    while True:\n",
    "        try:\n",
    "            response = urllib2.urlopen(request, timeout=4) #timeout set to 4 seconds; automatically retries if times out\n",
    "            raw = response.read()\n",
    "        except socket.timeout:\n",
    "            #print(\"Timeout raised and caught\")\n",
    "            continue\n",
    "        break\n",
    "    json_obj = json.loads(raw)\n",
    "    body = json_obj[\"response\"][\"hits\"]\n",
    "\n",
    "    num_hits = len(body)\n",
    "    if num_hits==0:\n",
    "        #print(\"\\t\\tNo results for: \" + song)\n",
    "        return\n",
    "\n",
    "    for result in body:\n",
    "        url = result[\"result\"][\"url\"]\n",
    "        \n",
    "        page = requests.get(url)\n",
    "        if page.status_code == 404:\n",
    "            return None\n",
    "\n",
    "        # Scrape the song lyrics from the HTML\n",
    "#         start_time = time.time()\n",
    "        html = bs4.BeautifulSoup(page.text, \"html.parser\")\n",
    "        title_genius = html.find(\"h1\", class_=\"header_with_cover_art-primary_info-title\").get_text().strip()\n",
    "        artist_genius = html.find(\"a\", class_=\"header_with_cover_art-primary_info-primary_artist\").get_text().strip()\n",
    "        if (title_genius == song.strip() ):#and artist_genius == artist):\n",
    "            lyrics = html.find(\"div\", class_=\"lyrics\").get_text()\n",
    "            lyrics = re.sub('(\\[.*?\\])*', '', lyrics)\n",
    "            lyrics = re.sub('\\n{2}', '\\n', lyrics)  # Gaps between verses\n",
    "\n",
    "            lyrics = unicodedata.normalize('NFKD', lyrics).encode('ascii','ignore')\n",
    "#             last_time = time.time()\n",
    "#             print('MINE time: {}'.format(last_time - start_time))\n",
    "            return lyrics.strip('\\n')\n",
    "    return None    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removePunctuation(tokens):\n",
    "    \"\"\"\n",
    "    This function finds punctuation (apart from '#' symbols) from each string token inside the provided token list\n",
    "    \n",
    "    arguments: tokens: list of strings\n",
    "    returns: list of strings (tokens)\n",
    "    \"\"\"\n",
    "    new_token_list = []\n",
    "    for token in tokens:\n",
    "        #returns a new string without punctuation\n",
    "        new_token = re.sub(r'[^\\w\\s#]','',token)\n",
    "        if (len(new_token) > 0):\n",
    "            new_token_list.append(new_token)\n",
    "    return new_token_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These two functions below can be used interchangaebly, depending on what the developer wants to achieve. \n",
    "- `getLyricsAllSongs`, fetches the lyrics for all songs of every one of the Top 700 Artists\n",
    "- `getLyricsTopsters`, fetches the lyrics for the Top 10 songs of every one of the Top 700 Artists\n",
    "\n",
    "Our focus on this research is on the results that can be attained from the Top 10 songs and, thus, we use `getLyricsTopsters`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLyricsAllSongs(artists_df):\n",
    "    for index, row in artists_df.iterrows():\n",
    "        artist_id = row['Artist_id']\n",
    "        artist_name = row['Artist']\n",
    "        artists_song_df = pd.read_csv('./songs/songs_'+artist_id+'.csv')\n",
    "        getLyrics(artist_id, artist_name, artists_song_df)\n",
    "\n",
    "        \n",
    "def getLyricsTopsters(artists_df):\n",
    "    for index, row in artists_df.iterrows():\n",
    "        artist_id = row['Artist_id']\n",
    "        artist_name = row['Artist']\n",
    "        artists_song_df = pd.read_csv('./topsters/songs_'+artist_id+'.csv')\n",
    "        getLyrics(artist_id, artist_name, artists_song_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`getLyrics` is the main utility function which creates an artist's file and gets the lyrics for all designated songs of an artist (depending on what is passed on `artists_song_df`).\n",
    "\n",
    "Each lyric `.csv` file includes the following fields: __'Artist', 'Artist id','Song','Song id','Lyrics'__\n",
    "\n",
    "Songs which include the strings _'strumental'_ and _'emix'_ are skipped (we deliberately do not have a first character for the words to avoid the need of capitalization or lowerification and achieve better performance with the same results). \n",
    "\n",
    "Furthermore, we remove any parentheses from the song title, as in the overwhelming majority of the cases it includes information about the song's current mix or version, which is not included in the lyric's page as well.\n",
    "\n",
    "Afterward we try to fetch the lyrics from the following services (in the presented order):\n",
    "1. AZLyrics\n",
    "2. LyricWikia\n",
    "3. Genius\n",
    "\n",
    "Finally we remove all punctuation from each lyric file and add a row on the `.csv`\n",
    "\n",
    "If a corresponding lyric file already exists for the artist in question, then the algorithm returns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLyrics(artist_id, artist_name, artists_song_df):\n",
    "    entered = False\n",
    "    if (os.path.exists(\"./lyrics/lyrics_\"+str(artist_id)+\".csv\")):\n",
    "#         print(\"{} already exists\".format(\"./lyrics/lyrics_\"+str(artist_id)+\".csv\"))\n",
    "        return\n",
    "    fileCsv_song_lyrics = csv.writer(open('./lyrics/lyrics_'+artist_id+'.csv', \"w+\"))\n",
    "    fileCsv_song_lyrics.writerow(['Artist', 'Artist_id','Song','Song_id','Lyrics'])\n",
    "    unique_song_list = []\n",
    "    for index_song, row_song in artists_song_df.iterrows():\n",
    "    #         print(row_song['Song'])\n",
    "        if (not(row_song['Song'] in unique_song_list)):\n",
    "            unique_song_list.append(row_song['Song'])\n",
    "            lyrics = None\n",
    "            if (not('strumental' in row_song['Song'] and 'emix' in row_song['Song'])):\n",
    "                song_name_wo_parentheses = re.sub(r'\\([^()]*\\)', '', row_song['Song'])\n",
    "#                 print artist_name\n",
    "#                 print \"====\"+song_name_wo_parentheses\n",
    "                try:\n",
    "                    wd = lyrics(artist_name, song_name_wo_parentheses)\n",
    "                    if ('Error' in wd):\n",
    "                        wd = lyrics(artist_name, row_song['Song'])\n",
    "                    if ('Error' in wd):\n",
    "                        raise Exception\n",
    "            #             print(song_name_wo_parentheses +' - Unable to find lyrics in AZ')\n",
    "                    else:\n",
    "                        lyrics = wd\n",
    "#                         print(row_song['Song'] +' - FOUND LYRICS in AZ')\n",
    "\n",
    "                except: #if shadow banned from AZLyrics\n",
    "#                     print('\\tAZ failed')\n",
    "                    try:\n",
    "                        lyrics = lyricwikia.get_lyrics(artist_name, song_name_wo_parentheses)\n",
    "                    except:\n",
    "#                         print('\\tLyric Wikia failed')\n",
    "                        lyrics = genius_Lyrics(artist_name, song_name_wo_parentheses)\n",
    "                        if (lyrics == None):\n",
    "                            pass\n",
    "#                             print(\"\\tGenius failed\")\n",
    "            if (not(lyrics == None) and not('Unfortunately, we are not licensed' in lyrics)):\n",
    "                entered = True\n",
    "                #tokenize lyrics\n",
    "                lyrics = nltk.word_tokenize(lyrics)\n",
    "                lyrics = removePunctuation(lyrics)\n",
    "                if isinstance(lyrics, list):\n",
    "                    lyric_string = \"\"\n",
    "                    for lyric in lyrics:\n",
    "                        lyric_string = lyric_string + \" \" + lyric\n",
    "                    lyrics = lyric_string\n",
    "                fileCsv_song_lyrics.writerow([artist_name, artist_id,row_song['Song'],row_song['Song_id'],lyrics])           #do NOT write in the CSV if you cannot find the lyrics\n",
    "#                 print(\"\\tADDED LYRICS\")\n",
    "    if not(entered):\n",
    "        pass\n",
    "#         print('\\tNO SONG FOR ARTIST {}'.format(artist_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "getLyricsTopsters(artists_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
